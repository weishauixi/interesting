{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "机器学习\n",
   "id": "b4f447c25670ef0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "人工智能三大概念：AI 机器学习（ML）和深度学习（DL）",
   "id": "535e3ab67e832693"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import sklearn",
   "id": "95dbb52cee149bab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "机器学习建模流程:\n",
    "1."
   ],
   "id": "6aad26a27c476de5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T14:31:34.484692Z",
     "start_time": "2025-12-16T14:31:29.600473Z"
    }
   },
   "cell_type": "markdown",
   "source": "KNN算法",
   "id": "666ab25f7ddf27c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#1.导包\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#2.准备数据集\n",
    "x_train=[[0],[1],[2],[3]]\n",
    "y_train=[0,0,1,1]\n",
    "x_test=[[5]]\n",
    "#3.创建模型\n",
    "model=KNeighborsClassifier(n_neighbors=2)\n",
    "#4.模型训练\n",
    "model.fit(x_train,y_train)\n",
    "#5.模型预测\n",
    "y_pre=model.predict(x_test)\n",
    "print(y_pre)"
   ],
   "id": "9a81eba37e4f9ce5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#1.导包\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "#2.准备数据集\n",
    "x_train=[[0,0,1],[1,1,0],[3,10,10],[4,11,12]]\n",
    "y_train=[0.1,0.2,0.3,0.4]\n",
    "x_test=[[3,10,11]]\n",
    "#3.创建模型\n",
    "model=KNeighborsRegressor(n_neighbors=2)\n",
    "#4.模型训练\n",
    "model.fit(x_train,y_train)\n",
    "#5.模型预测\n",
    "y_pre=model.predict(x_test)\n",
    "print(y_pre)"
   ],
   "id": "e27fdca83725a3f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "特征与处理之归一化操作（x=(当前值-min)/(max-min)）(处理小数据集适用 容易受到最大值最小值影响)",
   "id": "cce828a8e7d900ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c0a2587b53cdbf8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x_train=[[90,2,10,40],[60,4,15,45],[75,3,13,46]]\n",
    "#2.创建归一化对象\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "#3.队员数据集进行归一化操作\n",
    "x_train_new=scaler.fit_transform(x_train)\n",
    "print(x_train_new)\n"
   ],
   "id": "81a2d01cf00bc27c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "数据标准化 结果=(x-mean)/标准差(都是为了解决量纲问题)\n",
    "\n"
   ],
   "id": "88810966426c5a11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "x_train=[[90,2,10,40],[60,4,15,45],[75,3,13,46]]\n",
    "#2.创建标准化化对象\n",
    "scaler=StandardScaler()\n",
    "#3.队员数据集进行归一化操作\n",
    "x_train_new=scaler.fit_transform(x_train)\n",
    "print(x_train_new)\n",
    "print(f'数据集的均值:{scaler.mean_}')"
   ],
   "id": "3d1b70655f947d73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "利用KNN算法对鸢尾花进行分类\n",
    "1.加载数据\n",
    "2.数据预处理\n",
    "3.特征工程\n",
    "4.模型训练\n",
    "5.模型评估\n",
    "6.模型预测\n"
   ],
   "id": "98f099de52af861e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 导入类库\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, precision_score\n",
    "\n",
    "\n",
    "#1.定义函数 加载鸢尾花数据集并查看数据集\n",
    "def dm01_loadris():\n",
    "    #1.加载鸢尾花数据集\n",
    "    iris_data=load_iris()\n",
    "    #2.查看数据集\n",
    "    print(f'数据集:{iris_data}')\n",
    "    print(f'数据集类型{type(iris_data)}')\n",
    "    #3.查看所有键\n",
    "    print(f'查看数据集所有键{iris_data.keys()}')\n",
    "    print(iris_data.target_names)\n",
    "    print(iris_data.feature_names)\n",
    "    print(iris_data.filename)\n",
    "\n",
    "#2.定义函数，绘制数据集散点图\n",
    "def dm02_show_iris():\n",
    "    iris_data=load_iris()\n",
    "    #2.把鸢尾花数据转化为Dataframe\n",
    "    iris_df=pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "    #3.给df搞标签列\n",
    "    iris_df['labels']=iris_data.target\n",
    "    print(iris_df)\n",
    "    #4.绘制散点图\n",
    "    sns.lmplot(data=iris_df,x='sepal length (cm)',y='sepal width (cm)',hue='labels',fit_reg=False)\n",
    "    #5.设置标题\n",
    "    plt.title('iris data')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "#3.切分训练集测试集\n",
    "\n",
    "def dm03_split_train_test():\n",
    "    iris_data=load_iris()\n",
    "    x_train,x_test,y_train,y_test=train_test_split(iris_data.data,iris_data.target,test_size=0.2,random_state=42)\n",
    "    print(x_train,x_test,y_train,y_test,len(x_train),len(x_test),len(y_train),len(y_test))\n",
    "#4.实现鸢尾花完整案例 收集数据 预处理 标准化 模型训练 评估 预测\n",
    "def dm04_iris_evaluate_test():\n",
    "    #1.加载数据\n",
    "    iris_data=load_iris()\n",
    "    #2.数据预处理\n",
    "    x_train,x_test,y_train,y_test=train_test_split(iris_data.data,iris_data.target,test_size=0.2,random_state=42)\n",
    "    #3.特征工程\n",
    "    #思考1：特征都是用的不用选\n",
    "    #思考二：特征预处理：因为原数据差别不大 无需预处理 但更完善\n",
    "    #3.1创建标准化\n",
    "    transfer=StandardScaler()\n",
    "    #3.2对特征列进行标准化\n",
    "    #fit_transform 兼具fit和transform功能 即：训练 转换 该函数适用于：第一次进行标准化的时候，一般用于处理训练集\n",
    "\n",
    "    x_train=transfer.fit_transform(x_train)\n",
    "    #transform 只有转化 该函数适用于 重复进行标准化动作 一般用于对测试集进行标准化\n",
    "    x_test=transfer.transform(x_test)\n",
    "    #4.模型训练\n",
    "    #4.1创建模型对象\n",
    "    estimator=KNeighborsClassifier(n_neighbors=3)\n",
    "    #4.2训练\n",
    "    estimator.fit(x_train,y_train)\n",
    "\n",
    "    #5.模型预测\n",
    "    #场景一：切分的测试集\n",
    "    y_pre=estimator.predict(x_test)\n",
    "    print(y_pre)\n",
    "    #场景二：对新的数据集搞\n",
    "    my_data=[[7.8,2.1,3.9,1.6]]\n",
    "    #shujuji标准化\n",
    "    my_data=transfer.transform(my_data)\n",
    "    y_pre_new=estimator.predict(my_data)\n",
    "    print(y_pre_new)\n",
    "    #5.4查看上述数据集每种分类的概率\n",
    "    y_pre_proba=estimator.predict_proba(my_data)\n",
    "    print(y_pre_proba)\n",
    "    #6.模型预测\n",
    "    #方式1：直接评分 基于测试机的标签 训练集的标签\n",
    "    print(f'正确率:{estimator.score(x_test,y_test)}')\n",
    "    #方式2：基于测试机的标签和预测结果进行评分\n",
    "    print(f'正确率：{accuracy_score(y_test,y_pre)}')\n",
    "\n",
    "#5.测试\n",
    "if __name__ == '__main__':\n",
    "    dm01_loadris()\n",
    "    dm02_show_iris()\n",
    "    dm03_split_train_test()\n",
    "    dm04_iris_evaluate_test()\n"
   ],
   "id": "99613724ed52eb0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "#1.定义函数 加载鸢尾花数据集并查看数据集\n",
    "def dm01_loadris():\n",
    "    #1.加载鸢尾花数据集\n",
    "    iris_data=load_iris()\n",
    "    #2.查看数据集\n",
    "    print(f'数据集:{iris_data}')\n",
    "    print(f'数据集类型{type(iris_data)}')\n",
    "    #3.查看所有键\n",
    "    print(f'查看数据集所有键{iris_data.keys()}')\n",
    "    print(iris_data.target_names)\n",
    "    print(iris_data.feature_names)\n",
    "    print(iris_data.filename)\n",
    "\n",
    "#2.定义函数，绘制数据集散点图\n",
    "def dm02_show_iris():\n",
    "    iris_data=load_iris()\n",
    "    #2.把鸢尾花数据转化为Dataframe\n",
    "    iris_df=pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "    #3.给df搞标签列\n",
    "    iris_df['labels']=iris_data.target\n",
    "    print(iris_df)\n",
    "    #4.绘制散点图\n",
    "    sns.lmplot(data=iris_df,x='sepal length (cm)',y='sepal width (cm)',hue='labels',fit_reg=False)\n",
    "    #5.设置标题\n",
    "    plt.title('iris data')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "#3.切分训练集测试集\n",
    "\n",
    "def dm03_split_train_test():\n",
    "    iris_data=load_iris()\n",
    "    x_train,x_test,y_train,y_test=train_test_split(iris_data.data,iris_data.target,test_size=0.2,random_state=42)\n",
    "    print(x_train,x_test,y_train,y_test,len(x_train),len(x_test),len(y_train),len(y_test))\n",
    "#4.实现鸢尾花完整案例 收集数据 预处理 标准化 模型训练 评估 预测\n",
    "def dm04_iris_evaluate_test():\n",
    "    #1.加载数据\n",
    "    iris_data=load_iris()\n",
    "    #2.数据预处理\n",
    "    x_train,x_test,y_train,y_test=train_test_split(iris_data.data,iris_data.target,test_size=0.2,random_state=42)\n",
    "    #3.特征工程\n",
    "    #思考1：特征都是用的不用选\n",
    "    #思考二：特征预处理：因为原数据差别不大 无需预处理 但更完善\n",
    "    #3.1创建标准化\n",
    "    transfer=StandardScaler()\n",
    "    #3.2对特征列进行标准化\n",
    "    #fit_transform 兼具fit和transform功能 即：训练 转换 该函数适用于：第一次进行标准化的时候，一般用于处理训练集\n",
    "\n",
    "    x_train=transfer.fit_transform(x_train)\n",
    "    #transform 只有转化 该函数适用于 重复进行标准化动作 一般用于对测试集进行标准化\n",
    "    x_test=transfer.transform(x_test)\n",
    "    #4.模型训练\n",
    "    #4.1创建模型对象\n",
    "    estimator=KNeighborsClassifier()\n",
    "\n",
    "    #使用交叉验证\n",
    "    para_grid={'n_neighbors':[2,3,4,5,6,7,8,9,10,11]}\n",
    "    #创建Grid 找到最优参数\n",
    "    #参一：要计算的模型对象\n",
    "    #参二：该模型超参可能出现的值\n",
    "    #参三：交叉验证的折数\n",
    "    #返回值estimator：处理后的模型对象\n",
    "    estimator=GridSearchCV(estimator=estimator,param_grid=para_grid,cv=4)\n",
    "    #训练\n",
    "    estimator.fit(x_train,y_train)\n",
    "    print(f'最有评分:{estimator.best_score_}')\n",
    "    print(estimator.best_params_)\n",
    "    print(estimator.best_estimator_)\n",
    "    print(estimator.cv_results_)\n",
    "\n",
    "    #4.2训练\n",
    "    estimator.fit(x_train,y_train)\n",
    "\n",
    "    #5.模型预测\n",
    "    #场景一：切分的测试集\n",
    "    y_pre=estimator.predict(x_test)\n",
    "    print(y_pre)\n",
    "    #场景二：对新的数据集搞\n",
    "    my_data=[[7.8,2.1,3.9,1.6]]\n",
    "    #shujuji标准化\n",
    "    my_data=transfer.transform(my_data)\n",
    "    y_pre_new=estimator.predict(my_data)\n",
    "    print(y_pre_new)\n",
    "    #5.4查看上述数据集每种分类的概率\n",
    "    y_pre_proba=estimator.predict_proba(my_data)\n",
    "    print(y_pre_proba)\n",
    "    #6.模型预测\n",
    "    #方式1：直接评分 基于测试机的标签 训练集的标签\n",
    "    print(f'正确率:{estimator.score(x_test,y_test)}')\n",
    "    #方式2：基于测试机的标签和预测结果进行评分\n",
    "    print(f'正确率：{accuracy_score(y_test,y_pre)}')\n",
    "#模型评估\n",
    "\n",
    "#5.测试\n",
    "if __name__ == '__main__':\n",
    "    dm01_loadris()\n",
    "    dm02_show_iris()\n",
    "    dm03_split_train_test()\n",
    "    dm04_iris_evaluate_test()\n"
   ],
   "id": "cbf744096174fbe0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "手写数字识别",
   "id": "66dbd2eb10ae016e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "def show_digit(idx):\n",
    "    # 1 加载数据\n",
    "    data = pd.read_csv('data/手写数字识别.csv')\n",
    "    if idx < 0 or idx > len(data) - 1:\n",
    "        return\n",
    "    # 2 打印数据基本信息\n",
    "    x = data.iloc[:, 1:]\n",
    "    y = data.iloc[:, 0]\n",
    "    print('数据基本信息：', x.shape)\n",
    "    print('类别数据比例：', Counter(y))\n",
    "\n",
    "    print('当前数字的标签为：', y[idx])\n",
    "\n",
    "    # 3 显示指定的图片 # data修改为ndarray 类型\n",
    "    data_ = x.iloc[idx].values\n",
    "    # 将数据形状修改为 28*28\n",
    "    data_ = data_.reshape(28, 28)\n",
    "    # 关闭坐标轴标签\n",
    "    plt.axis('off')\n",
    "    # 显示图像\n",
    "    plt.imshow(data_, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def train_model():\n",
    "    # 1 加载手写数字数据集\n",
    "    data = pd.read_csv('data/手写数字识别.csv')\n",
    "\n",
    "    # 2 数据预处理 归一化\n",
    "    x = data.iloc[:, 1:] / 255\n",
    "    y = data.iloc[:, 0]\n",
    "\n",
    "    # 3 分割数据集\n",
    "    split_data = train_test_split(x, y, test_size=0.2, stratify=y, random_state=0)\n",
    "    x_train, x_test, y_train, y_test = split_data\n",
    "\n",
    "    # 4 模型训练\n",
    "    estimator = KNeighborsClassifier(n_neighbors=3)\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    # 5 模型评估\n",
    "    acc = estimator.score(x_test, y_test)\n",
    "    print('测试集准确率: %.2f' % acc)\n",
    "\n",
    "    # 6 模型保存\n",
    "    joblib.dump(estimator, 'model/knn.pth')\n",
    "\n",
    "def test_model():\n",
    "    # 1 读取图片数据\n",
    "    img = plt.imread('data/demo.png')\n",
    "    plt.imshow(img)\n",
    "\n",
    "    # 2 加载模型\n",
    "    knn = joblib.load('model/knn.pth')\n",
    "\n",
    "    # 3 预测图片\n",
    "    y_pred = knn.predict(img.reshape(1, -1))\n",
    "    print('您绘制的数字是：', y_pred)\n"
   ],
   "id": "c72671aec62b6f2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "线性回归",
   "id": "d29275edcf1ed416"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "x_train=[[160],[166],[172],[174],[180]]\n",
    "y_train=[56.3,60.6,65.1,68.5,75]\n",
    "x_test=[[176]]\n",
    "estimator=LinearRegression()\n",
    "estimator.fit(x_train,y_train)\n",
    "#可以查看下权重和斜率\n",
    "print(estimator.coef_)\n",
    "print(estimator.intercept_)\n",
    "\n",
    "y_pred=estimator.predict(x_test)\n",
    "print(y_pred)"
   ],
   "id": "b086f21c4fc6ddb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import root_mean_squared_error,mean_absolute_error\n",
    "#银行信贷 梯度下降求解\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "\n",
    "#波士顿房价预测\n",
    "#1。加载数据\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "# print(f'原始数据:{data.shape}')\n",
    "# print(data[:5])\n",
    "#2.数据的预处理\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "#3.特征工程\n",
    "#3.1创建标准化对象\n",
    "transfer=StandardScaler()\n",
    "#3.2训练集标准化\n",
    "x_train=transfer.fit_transform(x_train)\n",
    "x_test=transfer.transform(x_test)\n",
    "#4.模型训练\n",
    "#4.1创建线性回归正规方程\n",
    "estimator=LinearRegression(fit_intercept=True)\n",
    "estimator.fit(x_train,y_train)\n",
    "#4.2打印权重和偏置\n",
    "print(f'权重{estimator.coef_}')\n",
    "print(estimator.intercept_)\n",
    "\n",
    "#5。模型预测\n",
    "y_pre=estimator.predict(x_test)\n",
    "\n",
    "#6.模型评估\n",
    "print(f'均方误差：{mean_squared_error(y_test,y_pred)}')\n",
    "print(f'均方根误差：{root_mean_squared_error(y_test,y_pred)}')\n",
    "print(f'平均绝对误差：{mean_absolute_error(y_test,y_pred)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#梯度下降法\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "#银行信贷 梯度下降求解\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "\n",
    "#波士顿房价预测\n",
    "#1。加载数据\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "# print(f'原始数据:{data.shape}')\n",
    "# print(data[:5])\n",
    "#2.数据的预处理\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "#3.特征工程\n",
    "#3.1创建标准化对象\n",
    "transfer=StandardScaler()\n",
    "#3.2训练集标准化\n",
    "x_train=transfer.fit_transform(x_train)\n",
    "x_test=transfer.transform(x_test)\n",
    "#4.模型训练\n",
    "#4.1创建线性回归正规方程\n",
    "estimator=SGDRegressor(fit_intercept=True,learning_rate='constant',max_iter=10000,eta0=0.01)\n",
    "estimator.fit(x_train,y_train)\n",
    "#4.2打印权重和偏置\n",
    "print(f'权重{estimator.coef_}')\n",
    "print(estimator.intercept_)\n",
    "\n",
    "#5。模型预测\n",
    "y_pre=estimator.predict(x_test)\n",
    "\n",
    "#6.模型评估\n",
    "print(f'均方误差：{mean_squared_error(y_test,y_pred)}')\n",
    "print(f'均方根误差：{root_mean_squared_error(y_test,y_pred)}')\n",
    "print(f'平均绝对误差：{mean_absolute_error(y_test,y_pred)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "a74dfe013b8864cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#欠拟合过程\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error # 计算均方误差\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def dm01_under_fitting():\n",
    "    # 1 准备数据xy(增加上噪声)\n",
    "    np.random.seed(666)\n",
    "    x = np.random.uniform(-3, 3, size=100)\n",
    "    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)\n",
    "\n",
    "    # 2 实例化线性回归模型\n",
    "    estimator = LinearRegression()\n",
    "\n",
    "    # 3 训练模型\n",
    "    X = x.reshape(-1, 1)\n",
    "    estimator.fit(X, y)\n",
    "\n",
    "    # 4 模型预测\n",
    "    y_predict = estimator.predict(X)\n",
    "\n",
    "    # 5 计算均方误差\n",
    "    myret = mean_squared_error(y, y_predict)\n",
    "    print('myret-->', myret)\n",
    "\n",
    "    # 6 画图\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot(x, y_predict, color='r')\n",
    "    plt.show()\n",
    "if __name__ == '__main__':\n",
    "    dm01_under_fitting()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#刚好拟合\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error # 计算均方误差\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def dm01_模型欠拟合():\n",
    "    # 1 准备数据xy(增加上噪声)\n",
    "    np.random.seed(666)\n",
    "    x = np.random.uniform(-3, 3, size=100)\n",
    "    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)\n",
    "\n",
    "    # 2 实例化线性回归模型\n",
    "    estimator = LinearRegression()\n",
    "\n",
    "    # 3 训练模型\n",
    "    # 将x转换为矩阵形式 (100, 1)\n",
    "    X = x.reshape(-1, 1)\n",
    "    estimator.fit(X, y)\n",
    "\n",
    "    # 4 模型预测\n",
    "    y_predict = estimator.predict(X)\n",
    "\n",
    "    # 5 计算均方误差\n",
    "    myret = mean_squared_error(y, y_predict)\n",
    "    print('dm01 myret-->', myret)\n",
    "\n",
    "    # 6 画图\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot(x, y_predict, color='r')\n",
    "    plt.title(\"Underfitting (Linear Fit)\")\n",
    "    plt.show()\n",
    "\n",
    "def dm02_模型ok():\n",
    "    # 1 准备数据xy(增加上噪声)\n",
    "    np.random.seed(666)\n",
    "    x = np.random.uniform(-3, 3, size=100)\n",
    "    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)\n",
    "\n",
    "    # 2 实例化线性回归模型\n",
    "    estimator = LinearRegression()\n",
    "\n",
    "    # 3 训练模型\n",
    "    X = x.reshape(-1, 1)\n",
    "    # print('X.shape-->', X.shape)\n",
    "\n",
    "    # 数据增加二次项，通过 hstack 将 X 和 X^2 拼接\n",
    "    X2 = np.hstack([X, X ** 2])\n",
    "\n",
    "    estimator.fit(X2, y)\n",
    "\n",
    "    # 4 模型预测\n",
    "    y_predict = estimator.predict(X2)\n",
    "\n",
    "    # 5 计算均方误差\n",
    "    myret = mean_squared_error(y, y_predict)\n",
    "    print('dm02 myret-->', myret)\n",
    "\n",
    "    # 6 画图\n",
    "    plt.scatter(x, y)\n",
    "    # plt.plot(x, y_predict, color='r') # 直接画图会乱，因为x是无序的\n",
    "\n",
    "    # 画图plot折线图时 需要对x进行排序, 取x排序后对应的y值\n",
    "    # np.argsort(x) 返回的是排序后的索引\n",
    "    plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')\n",
    "    plt.title(\"Better Fit (Polynomial)\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 运行第一个函数：演示欠拟合（直线拟合曲线）\n",
    "    dm01_模型欠拟合()\n",
    "\n",
    "    # 运行第二个函数：演示效果较好的模型（引入二次项）\n",
    "    dm02_模型ok()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error # 计算均方误差\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def dm01_模型欠拟合():\n",
    "    # 1 准备数据xy(增加上噪声)\n",
    "    np.random.seed(666)\n",
    "    x = np.random.uniform(-3, 3, size=100)\n",
    "    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)\n",
    "\n",
    "    # 2 实例化线性回归模型\n",
    "    estimator = LinearRegression()\n",
    "\n",
    "    # 3 训练模型\n",
    "    X = x.reshape(-1, 1)\n",
    "    estimator.fit(X, y)\n",
    "\n",
    "    # 4 模型预测\n",
    "    y_predict = estimator.predict(X)\n",
    "\n",
    "    # 5 计算均方误差\n",
    "    myret = mean_squared_error(y, y_predict)\n",
    "    print('dm01_欠拟合 myret-->', myret)\n",
    "\n",
    "    # 6 画图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Underfitting (Linear Model)\")\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot(x, y_predict, color='r')\n",
    "    plt.show()\n",
    "\n",
    "def dm02_模型ok():\n",
    "    # 1 准备数据xy(增加上噪声)\n",
    "    np.random.seed(666)\n",
    "    x = np.random.uniform(-3, 3, size=100)\n",
    "    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)\n",
    "\n",
    "    # 2 实例化线性回归模型\n",
    "    estimator = LinearRegression()\n",
    "\n",
    "    # 3 训练模型\n",
    "    X = x.reshape(-1, 1)\n",
    "    # print('X.shape-->', X.shape)\n",
    "\n",
    "    # 数据增加二次项\n",
    "    X2 = np.hstack([X, X ** 2])\n",
    "    estimator.fit(X2, y)\n",
    "\n",
    "    # 4 模型预测\n",
    "    y_predict = estimator.predict(X2)\n",
    "\n",
    "    # 5 计算均方误差\n",
    "    myret = mean_squared_error(y, y_predict)\n",
    "    print('dm02_拟合良好 myret-->', myret)\n",
    "\n",
    "    # 6 画图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Good Fit (Polynomial Degree 2)\")\n",
    "    plt.scatter(x, y)\n",
    "    # plt.plot(x, y_predict, color='r')\n",
    "    # 画图plot折线图时 需要对x进行排序, 取x排序后对应的y值\n",
    "    plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')\n",
    "    plt.show()\n",
    "\n",
    "def dm03_模型过拟合():\n",
    "    # 1 准备数据xy(增加上噪声)\n",
    "    np.random.seed(666)\n",
    "    x = np.random.uniform(-3, 3, size=100)\n",
    "    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)\n",
    "\n",
    "    # 2 实例化线性回归模型\n",
    "    estimator = LinearRegression()\n",
    "\n",
    "    # 3 训练模型\n",
    "    X = x.reshape(-1, 1)\n",
    "    # print('X.shape-->', X.shape)\n",
    "\n",
    "    # 数据增加高次项 (一直加到10次方)，导致特征过多\n",
    "    X3 = np.hstack([X, X**2, X**3, X**4, X**5, X**6, X**7, X**8, X**9, X**10])\n",
    "    estimator.fit(X3, y)\n",
    "\n",
    "    # 4 模型预测\n",
    "    y_predict = estimator.predict(X3)\n",
    "\n",
    "    # 5 计算均方误差\n",
    "    myret = mean_squared_error(y, y_predict)\n",
    "    print('dm03_过拟合 myret-->', myret)\n",
    "\n",
    "    # 6 画图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Overfitting (Polynomial Degree 10)\")\n",
    "    plt.scatter(x, y)\n",
    "    # 画图时输入的x数据: 要求是从小到大\n",
    "    plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 依次运行三个函数查看效果\n",
    "    print(\"--- 1. 欠拟合示例 ---\")\n",
    "    dm01_模型欠拟合()\n",
    "\n",
    "    print(\"\\n--- 2. 拟合良好示例 ---\")\n",
    "    dm02_模型ok()\n",
    "\n",
    "    print(\"\\n--- 3. 过拟合示例 ---\")\n",
    "    dm03_模型过拟合()\n"
   ],
   "id": "1acebb707989dd65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#解决方法 正则化\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error # 计算均方误差\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def dm01_模型欠拟合():\n",
    "    # 1 准备数据xy(增加上噪声)\n",
    "    np.random.seed(666)\n",
    "    x = np.random.uniform(-3, 3, size=100)\n",
    "    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)\n",
    "\n",
    "    # 2 实例化线性回归模型\n",
    "    estimator = LinearRegression()\n",
    "\n",
    "    # 3 训练模型\n",
    "    X = x.reshape(-1, 1)\n",
    "    estimator.fit(X, y)\n",
    "\n",
    "    # 4 模型预测\n",
    "    y_predict = estimator.predict(X)\n",
    "\n",
    "    # 5 计算均方误差\n",
    "    myret = mean_squared_error(y, y_predict)\n",
    "    print('dm01_欠拟合 myret-->', myret)\n",
    "\n",
    "    # 6 画图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Underfitting (Linear)\")\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot(x, y_predict, color='r') # 注意：这里x未排序，直接画直线没问题，但如果是曲线会乱\n",
    "    plt.show()\n",
    "\n",
    "def dm02_模型ok():\n",
    "    # 1 准备数据xy(增加上噪声)\n",
    "    np.random.seed(666)\n",
    "    x = np.random.uniform(-3, 3, size=100)\n",
    "    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)\n",
    "\n",
    "    # 2 实例化线性回归模型\n",
    "    estimator = LinearRegression()\n",
    "\n",
    "    # 3 训练模型\n",
    "    X = x.reshape(-1, 1)\n",
    "    # print('X.shape-->', X.shape)\n",
    "\n",
    "    # 数据增加二次项\n",
    "    X2 = np.hstack([X, X ** 2]) # 数据增加二次项\n",
    "    estimator.fit(X2, y)\n",
    "\n",
    "    # 4 模型预测\n",
    "    y_predict = estimator.predict(X2)\n",
    "\n",
    "    # 5 计算均方误差\n",
    "    myret = mean_squared_error(y, y_predict)\n",
    "    print('dm02_拟合良好 myret-->', myret)\n",
    "\n",
    "    # 6 画图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Good Fit (Degree 2)\")\n",
    "    plt.scatter(x, y)\n",
    "    # plt.plot(x, y_predict, color='r')\n",
    "    # 画图plot折线图时 需要对x进行排序, 取x排序后对应的y值\n",
    "    plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')\n",
    "    plt.show()\n",
    "\n",
    "def dm03_模型过拟合():\n",
    "    # 1 准备数据xy(增加上噪声)\n",
    "    np.random.seed(666)\n",
    "    x = np.random.uniform(-3, 3, size=100)\n",
    "    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)\n",
    "\n",
    "    # 2 实例化线性回归模型\n",
    "    estimator = LinearRegression()\n",
    "\n",
    "    # 3 训练模型\n",
    "    X = x.reshape(-1, 1)\n",
    "    # print('X.shape-->', X.shape)\n",
    "\n",
    "    # 数据增加高次项 (一直加到10次方)\n",
    "    X3 = np.hstack([X, X**2, X**3, X**4, X**5, X**6, X**7, X**8, X**9, X**10]) # 数据增加高次项\n",
    "    estimator.fit(X3, y)\n",
    "\n",
    "    # 4 模型预测\n",
    "    y_predict = estimator.predict(X3)\n",
    "\n",
    "    # 5 计算均方误差\n",
    "    myret = mean_squared_error(y, y_predict)\n",
    "    print('dm03_过拟合 myret-->', myret)\n",
    "\n",
    "    # 6 画图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Overfitting (Degree 10)\")\n",
    "    plt.scatter(x, y)\n",
    "    # 画图时输入的x数据: 要求是从小到大\n",
    "    plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')\n",
    "    plt.show()\n",
    "\n",
    "def dm04_模型过拟合_L1正则化():\n",
    "    # 1 准备数据xy(增加上噪声)\n",
    "    np.random.seed(666)\n",
    "    x = np.random.uniform(-3, 3, size=100)\n",
    "    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)\n",
    "\n",
    "    # 2 实例化L1正则化模型 做实验:alpha惩罚力度越来越大k值越来越小,返回会欠拟合\n",
    "    # 注意: normalize=True 在新版sklearn中已弃用，如果报错请删除该参数\n",
    "    try:\n",
    "        estimator = Lasso(alpha=0.005, normalize=True)\n",
    "    except TypeError:\n",
    "        print(\"提示: 当前sklearn版本不支持normalize参数，已自动移除\")\n",
    "        estimator = Lasso(alpha=0.005)\n",
    "\n",
    "    # 3 训练模型\n",
    "    X = x.reshape(-1, 1)\n",
    "    X3 = np.hstack([X, X**2, X**3, X**4, X**5, X**6, X**7, X**8, X**9, X**10])\n",
    "    estimator.fit(X3, y)\n",
    "\n",
    "    print('Lasso estimator.coef_', estimator.coef_)\n",
    "\n",
    "    # 4 模型预测\n",
    "    y_predict = estimator.predict(X3)\n",
    "\n",
    "    # 5 计算均方误差\n",
    "    myret = mean_squared_error(y, y_predict)\n",
    "    print('dm04_L1正则化 myret-->', myret)\n",
    "\n",
    "    # 6 画图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Lasso Regularization (L1)\")\n",
    "    plt.scatter(x, y)\n",
    "    # 画图时输入的x数据: 要求是从小到大\n",
    "    plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')\n",
    "    plt.show()\n",
    "\n",
    "def dm05_模型过拟合_L2正则化():\n",
    "    # 1 准备数据xy(增加上噪声)\n",
    "    np.random.seed(666)\n",
    "    x = np.random.uniform(-3, 3, size=100)\n",
    "    y = 0.5 * x ** 2 + x + 2 + np.random.normal(0, 1, size=100)\n",
    "\n",
    "    # 2 实例化L2正则化模型\n",
    "    # 注意: normalize=True 在新版sklearn中已弃用，如果报错请删除该参数\n",
    "    try:\n",
    "        estimator = Ridge(alpha=100, normalize=True)\n",
    "    except TypeError:\n",
    "        print(\"提示: 当前sklearn版本不支持normalize参数，已自动移除\")\n",
    "        estimator = Ridge(alpha=100)\n",
    "\n",
    "    # 3 训练模型\n",
    "    X = x.reshape(-1, 1)\n",
    "    X3 = np.hstack([X, X**2, X**3, X**4, X**5, X**6, X**7, X**8, X**9, X**10])\n",
    "    estimator.fit(X3, y)\n",
    "\n",
    "    print('Ridge estimator.coef_', estimator.coef_)\n",
    "\n",
    "    # 4 模型预测\n",
    "    y_predict = estimator.predict(X3)\n",
    "\n",
    "    # 5 计算均方误差\n",
    "    myret = mean_squared_error(y, y_predict)\n",
    "    print('dm05_L2正则化 myret-->', myret)\n",
    "\n",
    "    # 6 画图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Ridge Regularization (L2)\")\n",
    "    plt.scatter(x, y)\n",
    "    # 画图时输入的x数据: 要求是从小到大\n",
    "    plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 依次运行查看效果\n",
    "    dm01_模型欠拟合()\n",
    "    dm02_模型ok()\n",
    "    dm03_模型过拟合()\n",
    "    dm04_模型过拟合_L1正则化()\n",
    "    dm05_模型过拟合_L2正则化()\n"
   ],
   "id": "5109d8248badcebe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4d20ea4cb880c0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "data=pd.read_csv(\"C:/Users/王晋华/Desktop/breast-cancer-wisconsin.csv\")\n",
    "\n",
    "data.replace('?',np.nan,inplace=True)\n",
    "data.dropna(axis=0,inplace=True,ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "#特征工程 提取 预处理\n",
    "#提取特征与标签\n",
    "x=data.iloc[:,1:-1]\n",
    "y=data.iloc[:,-1]\n",
    "y=data['Class']\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=666)\n",
    "transformer = StandardScaler()\n",
    "x_train = transformer.fit_transform(x_train)\n",
    "x_test = transformer.transform(x_test)\n",
    "estimator = LogisticRegression()\n",
    "estimator.fit(x_train, y_train)\n",
    "y_predict = estimator.predict(x_test)\n",
    "print(estimator.score(x_test, y_test))\n",
    "print(accuracy_score(y_test, y_predict))#预测准确率并不能满足各种需求\n",
    "#要通过混淆矩阵来评测 即：精确率召回率 ROC曲线 AOC值\n",
    "#精确率：tp/(tp+fn) 召回率：tp/(tp+fn) F1:2*精确率*召回率/（精确率+召回率）\n",
    "#演示混淆矩阵\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics  import classification_report\n",
    "y_train=['恶性','恶性','恶性','恶性','恶性','恶性','良性','良性','良性','良性']\n",
    "y_pre_A=['良性','恶性','良性','良性','恶性','恶性','良性','良性','良性','良性']\n",
    "y_pre_B=['恶性','恶性','恶性','恶性','恶性','恶性','恶性','恶性','良性','恶性']\n",
    "\n",
    "label=['恶性','良性']\n",
    "df_label=['恶性（正例）','良性（反例）']\n",
    "cm_A=confusion_matrix(y_train, y_pre_A,labels=label)\n",
    "cm_B=confusion_matrix(y_train, y_pre_B,labels=label)\n",
    "\n",
    "df_A=pd.DataFrame(cm_A,index=label,columns=df_label)\n",
    "df_B=pd.DataFrame(cm_B)\n",
    "print(df_A)\n",
    "print(df_B)\n",
    "print(precision_score(y_train, y_pre_A, pos_label='恶性'))\n",
    "print(recall_score(y_train,y_pre_A,pos_label='恶性'))\n",
    "print(precision_score(y_train, y_pre_B, pos_label='恶性')\n",
    "print(classification_report(y_train,y_pre_A,labels=label,target_names=None)))"
   ],
   "id": "2ee23b065bf44df6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#真实案例\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#1.数据的预处理\n",
    "def data_processing():\n",
    "    df=pd.read_csv(\"C:/Users/王晋华/Desktop/churn.csv\")\n",
    "\n",
    "    df=pd.get_dummies(df,columns=['Churn','gender'])\n",
    "    df.drop(['Churn_No','gender_Male'],axis=1,inplace=True)\n",
    "    df.rename(columns={'Churn_Yes':'flag'})\n",
    "    print(df.head())\n",
    "    print(df.shape)\n",
    "\n",
    "\n",
    "#2.数据的可视化\n",
    "def data_visualization():\n",
    "    df=pd.read_csv(\"C:/Users/王晋华/Desktop/churn.csv\")\n",
    "\n",
    "    df=pd.get_dummies(df,columns=['Churn','gender'])\n",
    "    df.drop(['Churn_No','gender_Male'],axis=1,inplace=True)\n",
    "    df.rename(columns={'Churn_Yes':'flag'})\n",
    "\n",
    "    print(df.columns)\n",
    "    '''\n",
    "    Index(['Partner_att', 'Dependents_att', 'landline', 'internet_att',)\n",
    "       'internet_other', 'StreamingTV', 'StreamingMovies', 'Contract_Month',\n",
    "       'Contract_1YR', 'PaymentBank', 'PaymentCreditcard', 'PaymentElectronic',\n",
    "       'MonthlyCharges', 'TotalCharges', 'Churn_Yes', 'gender_Female'],\n",
    "      dtype='object')\n",
    "      '''\n",
    "    sns.countplot(data=df,x='Contract_Month',hue='Churn_Yes')\n",
    "#3.模型训练\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "def logic():\n",
    "    df=pd.read_csv(\"C:/Users/王晋华/Desktop/churn.csv\")\n",
    "\n",
    "    df=pd.get_dummies(df,columns=['Churn','gender'])\n",
    "    df.drop(['Churn_No','gender_Male'],axis=1,inplace=True)\n",
    "    df.rename(columns={'Churn_Yes':'flag'})\n",
    "    #提取特征\n",
    "    x=df[['Contract_Month','internet_other','PaymentElectronic' ]]\n",
    "    y=df['Churn_Yes']\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=666)\n",
    "\n",
    "    estimator = LogisticRegression()\n",
    "    estimator.fit(x_train,y_train)\n",
    "    y_pred=estimator.predict(x_test)\n",
    "    print(y_pred)\n",
    "    print(estimator.score(x_test,y_test))\n",
    "    print(accuracy_score(y_test,y_pred))\n",
    "\n",
    "#4.测试\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_processing()\n",
    "    data_visualization()\n",
    "    logic()"
   ],
   "id": "ab9f83bad83e5bae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "决策树",
   "id": "4a9983921899a2c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "明白条件熵 信息增益 以及信息熵 信息增益率=信息增益/特征熵 1/特征熵就是惩罚系数\n",
   "id": "35bdbc2b96aa3b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "def dm04_泰坦尼克():\n",
    "    # 1 读数据到内存\n",
    "    taitan_df = pd.read_csv(\"./data/titanic/train.csv\")\n",
    "    taitan_df.head()        # 查看前5条数据\n",
    "    taitan_df.info()         # 查看特性信息\n",
    "\n",
    "    # 2 数据基本处理\n",
    "    # 2-1 确定x y\n",
    "    x = taitan_df[['Pclass', 'Age', 'Sex']]\n",
    "    y = taitan_df['Survived']\n",
    "\n",
    "    # 2-2 缺失值处理\n",
    "    x=x.copy()\n",
    "    x['Age']=x['Age'].fillna(x['Age'].mean(), inplace=True)\n",
    "\n",
    "    # 2-3 类别型数据 one-hot编码\n",
    "    print('x-->1\\n', x)\n",
    "    x.info()\n",
    "    x = pd.get_dummies(x)\n",
    "    print('x-->2\\n', x)\n",
    "    x.info()\n",
    "\n",
    "    # 2-4 数据集划分\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=33)\n",
    "\n",
    "    # 3 模型训练 - 决策树分类器\n",
    "    dec_tree = DecisionTreeClassifier(random_state=33)\n",
    "    dec_tree.fit(x_train, y_train)\n",
    "\n",
    "    # 4 模型评估\n",
    "    y_pred = dec_tree.predict(x_test)\n",
    "    print(\"=\"*50)\n",
    "    print(\"模型分类评估报告：\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # 5 决策树可视化展示\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_tree(dec_tree, feature_names=x.columns, class_names=['遇难','存活'], filled=True, rounded=True, fontsize=10)\n",
    "    plt.title('泰坦尼克号生存预测-决策树模型', fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "    # 6 输出特征重要性\n",
    "    print(\"=\"*50)\n",
    "    print(\"特征重要性排序：\")\n",
    "    feature_importance = pd.DataFrame({'特征名':x.columns, '重要性':dec_tree.feature_importances_})\n",
    "    print(feature_importance.sort_values(by='重要性', ascending=False))\n",
    "\n",
    "# 调用函数执行\n",
    "if __name__=='__main__':\n",
    "\n",
    "    dm04_泰坦尼克()"
   ],
   "id": "6f5f56a1500c92eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T07:02:07.668705Z",
     "start_time": "2026-01-05T07:02:07.294335Z"
    }
   },
   "cell_type": "markdown",
   "source": "CART回归 和 线性回归对比\n",
   "id": "8f5611ed41d65550"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor # 回归决策树\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def dm01_回归分类():\n",
    "    # 1 准备数据\n",
    "    x = np.array(list(range(1,11))).reshape(-1, 1)\n",
    "    y = np.array([5.56, 5.70, 5.91, 6.40, 6.80, 7.05, 8.90, 8.70, 9.00, 9.05])\n",
    "    print('x-->\\n', x)\n",
    "    print('y-->\\n', y)\n",
    "\n",
    "    # 2 实例化模型 模型训练\n",
    "    model1 = DecisionTreeRegressor(max_depth=1,ccp_alpha=1.40000000e-03)\n",
    "    model2 = DecisionTreeRegressor(max_depth=3)\n",
    "    model3 = LinearRegression()\n",
    "    model1.fit(x, y)\n",
    "    model2.fit(x, y)\n",
    "    model3.fit(x, y)\n",
    "\n",
    "    # 3 模型预测 # 等差数组-按照间隔\n",
    "    x_test = np.arange(0.0, 10.0, 0.01).reshape(-1, 1)\n",
    "    y_pre1 = model1.predict(x_test)\n",
    "    y_pre2 = model2.predict(x_test)\n",
    "    y_pre3 = model3.predict(x_test)\n",
    "    print(y_pre1.shape, y_pre2.shape, y_pre3.shape)\n",
    "\n",
    "    # 4 结果可视化\n",
    "    plt.figure(figsize=(10, 6), dpi=100)\n",
    "    plt.scatter(x, y, label='data')\n",
    "\n",
    "    plt.plot(x_test, y_pre1, label='max_depth=1') # 深度1层\n",
    "    plt.plot(x_test, y_pre2, label='max_depth=3') # 深度3层\n",
    "    plt.plot(x_test, y_pre3, label='linear')\n",
    "    plt.xlabel('data')\n",
    "    plt.ylabel('target')\n",
    "    plt.title('DecisionTreeRegressor')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dm01_回归分类()"
   ],
   "id": "ba0789fc581d13f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#剪枝\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei'] # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "X= np.array(list(range(1,11))).reshape(-1, 1)\n",
    "y = np.array([5.56, 5.70, 5.91, 6.40, 6.80, 7.05, 8.90, 8.70, 9.00, 9.05])\n",
    "# 假设 X, y 已经准备好了\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# 1. 实例化一个不加限制的树（让它疯长）\n",
    "clf = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "# 2. 获取这一棵树的剪枝路径\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas  # 这里就是程序算出来的“候选alpha列表”\n",
    "impurities = path.impurities\n",
    "\n",
    "print(f\"提取到了 {len(ccp_alphas)} 个候选 alpha 值\")\n",
    "print(ccp_alphas)\n",
    "\n",
    "# 3. 循环测试每一个 alpha 的效果\n",
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeRegressor(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clfs.append(clf)\n",
    "\n",
    "# 4. 记录训练集和测试集的分数\n",
    "train_scores = [clf.score(X_train, y_train) for clf in clfs]\n",
    "test_scores = [clf.score(X_test, y_test) for clf in clfs]\n",
    "\n",
    "# 5. 可视化找最佳点\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"精度 (Score)\")\n",
    "ax.set_title(\"Alpha vs 精度 (训练集 vs 测试集)\")\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label=\"训练集\", drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label=\"测试集\", drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "id": "bf789b8c8019ed8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#随机森林算法\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "df=pd.read_csv(\"\")\n",
    "\n",
    "\n",
    "x=df[['Pclass','Sex','Age']].copy()\n",
    "y=df['Survived']\n",
    "x['Age']=x['Age'].fillna(x['Age'].mean(), inplace=False)\n",
    "x=pd.get_dummies(x)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "\n",
    "\n",
    "estimator1=DecisionTreeClassifier()\n",
    "estimator1.fit(x_train,y_train)\n",
    "y_pred=estimator1.predict(x_test)\n",
    "print(y_pred)\n",
    "print(estimator1.score(x_test,y_test))\n",
    "print('-'*23)\n",
    "\n",
    "\n",
    "\n",
    "estimator2=RandomForestClassifier(n_estimators=100,max_dept=None)\n",
    "estimator2.fit(x_train,y_train)\n",
    "y_pred2=estimator2.predict(x_test)\n",
    "print(y_pred2)\n",
    "print(estimator2.score(x_test,y_test))\n",
    "\n",
    "\n",
    "estimator3=RandomForestClassifier\n",
    "params={'n_estimators':[60,90,120,150],'max_depth':[3,5,7,9]}\n",
    "ge_estimator=GridSearchCV(estimator=estimator3,param_grid=params,scoring='accuracy',cv=2)\n",
    "ge_estimator.fit(x_train,y_train)\n",
    "y_pred3=ge_estimator.predict(x_test)\n",
    "print(y_pred3)\n",
    "print(ge_estimator.score(x_test,y_test))\n",
    "print('-'*23)\n"
   ],
   "id": "2ddfc6afd3e38d12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier # 集成学习\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def dm01_adaboost():\n",
    "\n",
    "\n",
    "    df_wine = pd.read_csv('\"C:/Users/王晋华/Desktop/红酒品质分类.csv\"')\n",
    "    df.info()\n",
    "\n",
    "    #2.1 从列表中过滤掉列表一 剩下2 3\n",
    "    df_wine=df_wine[df_wine['class label']!=1]\n",
    "\n",
    "\n",
    "    # 2-3 准备特征值和目标值\n",
    "    # 选取 'Alcohol' (酒精) 和 'Hue' (颜色/色调) 作为特征\n",
    "    # 注意：如果是内置数据集，确保列名已对应\n",
    "    x = df_wine[['Alcohol', 'Hue']].values\n",
    "    y = df_wine['Class label'].values\n",
    "\n",
    "    # 2-4 类别转化 y (2,3) => (0,1)\n",
    "    # 因为 AdaBoost 默认处理 0/1 标签\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    print('类别标签转化后的 y (前10个):', y[:10])\n",
    "\n",
    "    # 2-5 划分数据\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=22, test_size=0.2)\n",
    "    print(f\"训练集形状: {X_train.shape}, 测试集形状: {X_test.shape}\")\n",
    "\n",
    "\n",
    "    # --- 3. (补全部分) 模型训练 ---\n",
    "    # AdaBoost 的核心：弱分类器通常是一个“树桩”（max_depth=1 的决策树）\n",
    "    # 这种树很弱，只切一刀，但 AdaBoost 会把很多这样的树组合起来\n",
    "    estimator = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    print(estimator.score(X_test, y_test))\n",
    "\n",
    "\n",
    "    # n_estimators=50: 让50个弱分类器来投票\n",
    "    # learning_rate=1.0: 学习率，控制每个弱分类器的权重缩减\n",
    "    best_estimator = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "    model = AdaBoostClassifier(\n",
    "        estimator=base_estimator,\n",
    "        n_estimators=50,\n",
    "        learning_rate=1.0,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"开始训练 AdaBoost...\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # --- 4. (补全部分) 预测与评估 ---\n",
    "    y_predict = model.predict(X_test)\n",
    "\n",
    "    # 计算准确率\n",
    "    score = accuracy_score(y_test, y_predict)\n",
    "    print(\"=\" * 30)\n",
    "    print(f\"AdaBoost 预测准确率: {score:.4f}\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    # 打印一下真实的类别和预测的类别对比（前10个）\n",
    "    print(\"真实值:\", y_test[:10])\n",
    "    print(\"预测值:\", y_predict[:10])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dm01_adaboost()"
   ],
   "id": "f45a3eca5d792715",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "梯度提升树",
   "id": "1187b97c0a35aa7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T12:44:38.782557Z",
     "start_time": "2026-01-11T12:44:17.814488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def dm01_gbdtapi():\n",
    "    # --- 1. 读取数据 ---\n",
    "    try:\n",
    "        # 尝试读取本地文件\n",
    "        taitan_df = pd.read_csv('./data/titanic/train.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"未找到本地 csv，正在加载 seaborn 内置泰坦尼克数据作为替代...\")\n",
    "        import seaborn as sns\n",
    "        taitan_df = sns.load_dataset('titanic')\n",
    "        # 简单映射列名以匹配原代码逻辑\n",
    "        taitan_df.rename(columns={'survived': 'Survived', 'pclass': 'Pclass', 'age': 'Age', 'sex': 'Sex'}, inplace=True)\n",
    "\n",
    "\n",
    "    # --- 2. 数据预处理 ---\n",
    "    # 2-1 特征选择\n",
    "    taitan_df.info()\n",
    "    x = taitan_df[['Pclass', 'Age', 'Sex']].copy()\n",
    "    y = taitan_df['Survived'].copy()\n",
    "\n",
    "    # 2-2 缺失值处理\n",
    "    # 注意：inplace=True 在新版 pandas 中不推荐，建议使用赋值写法\n",
    "    x['Age'] = x['Age'].fillna(x['Age'].mean())\n",
    "\n",
    "    # 2-3 独热编码 (One-Hot)\n",
    "    # 这一步会将 'Sex' 列转换为 'Sex_female' 和 'Sex_male'\n",
    "    # 注意：'Pclass'如果是数字类型，get_dummies 默认不会处理它，若需处理需先转为 str\n",
    "    x = pd.get_dummies(x)\n",
    "\n",
    "    # 2-4 数据集划分\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=22, test_size=0.2)\n",
    "\n",
    "    # --- 3. GBDT 基础训练和评估 ---\n",
    "    print(\"=== 开始基础训练 ===\")\n",
    "    estimator = GradientBoostingClassifier(n_estimators=120, random_state=9)\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    base_score = estimator.score(x_test, y_test)\n",
    "    print(f\"GBDT 默认参数得分: {base_score:.4f}\")\n",
    "    print(estimator.score(x_test, y_test))\n",
    "    print(classification_report(y_test, estimator.predict(x_test)))\n",
    "\n",
    "    # --- 4. GBDT 网格搜索 (GridSearch) ---\n",
    "    print(\"\\n=== 开始网格搜索 ===\")\n",
    "    estimator = GradientBoostingClassifier()\n",
    "\n",
    "    # 定义参数字典\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [80,90,100, 110, 120, 130],  # 树的数量\n",
    "        \"max_depth\": [2, 3, 4,5],               # 树的深度\n",
    "        \"random_state\": [9]                   # 随机种子\n",
    "    }\n",
    "\n",
    "    # 实例化 GridSearchCV (cv=3 表示 3折交叉验证)\n",
    "    grid_search = GridSearchCV(estimator, param_grid=param_grid, cv=3)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    # 获取结果\n",
    "    print(f\"网格搜索最佳测试集得分: {grid_search.score(x_test, y_test):.4f}\")\n",
    "    print(\"最佳参数模型详情:\", grid_search.best_estimator_)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dm01_gbdtapi()"
   ],
   "id": "398858e28d6457f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未找到本地 csv，正在加载 seaborn 内置泰坦尼克数据作为替代...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   Survived     891 non-null    int64   \n",
      " 1   Pclass       891 non-null    int64   \n",
      " 2   Sex          891 non-null    object  \n",
      " 3   Age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n",
      "=== 开始基础训练 ===\n",
      "GBDT 默认参数得分: 0.7542\n",
      "0.7541899441340782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80       110\n",
      "           1       0.69      0.65      0.67        69\n",
      "\n",
      "    accuracy                           0.75       179\n",
      "   macro avg       0.74      0.74      0.74       179\n",
      "weighted avg       0.75      0.75      0.75       179\n",
      "\n",
      "\n",
      "=== 开始网格搜索 ===\n",
      "网格搜索最佳测试集得分: 0.7318\n",
      "最佳参数模型详情: GradientBoostingClassifier(learning_rate=3, max_depth=2, n_estimators=80,\n",
      "                           random_state=9)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "极限梯度提升树 XGBoost",
   "id": "36b62e124d22038d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T00:30:49.185062Z",
     "start_time": "2026-01-13T00:30:41.869944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import xgboost as xgb\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "# 基本数据处理\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def dm01_realdata():\n",
    "    # 1 加载训练集\n",
    "    data = pd.read_csv(\"C:/Users/王晋华/Desktop/红酒品质分类.csv\")\n",
    "    x = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1] - 3\n",
    "\n",
    "    # 2 数据集划分\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=22)\n",
    "\n",
    "    # 3 数据存储\n",
    "    pd.concat([x_train, y_train], axis=1).to_csv('C:/Users/王晋华/Desktop/红酒品质分类-train.csv')\n",
    "    pd.concat([x_test, y_test], axis=1).to_csv('C:/Users/王晋华/Desktop/红酒品质分类-test.csv')\n",
    "\n",
    "def dm02_训练模型():\n",
    "    # 1 加载数据集\n",
    "    train_data = pd.read_csv('C:/Users/王晋华/Desktop/红酒品质分类-train.csv')\n",
    "    test_data = pd.read_csv('C:/Users/王晋华/Desktop/红酒品质分类-test.csv')\n",
    "\n",
    "    # 2 准备数据 训练集测试集\n",
    "    x_train = train_data.iloc[:, :-1]\n",
    "    y_train = train_data.iloc[:, -1]\n",
    "    x_test = test_data.iloc[:, :-1]\n",
    "    y_test = test_data.iloc[:, -1]\n",
    "    print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "    # 3 xgb模型训练\n",
    "    estimator = xgb.XGBClassifier(n_estimators=100, objective='multi:softmax',\n",
    "                                  eval_metric='merror', eta=0.1, use_label_encoder=False, random_state=22)\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    # 4 xgb模型评估\n",
    "    y_pred = estimator.predict(x_test)\n",
    "    print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "    # 5 模型保存\n",
    "    joblib.dump(estimator, 'C:/Users/王晋华/Desktop/mymodelxgboost.pth')\n",
    "\n",
    "    from sklearn.utils import class_weight\n",
    "\n",
    "def dm03_训练模型():\n",
    "    # 1 加载数据集\n",
    "    train_data = pd.read_csv('C:/Users/王晋华/Desktop/红酒品质分类-train.csv')\n",
    "    test_data = pd.read_csv('C:/Users/王晋华/Desktop/红酒品质分类-test.csv')\n",
    "\n",
    "    # 2 准备数据 训练集测试集\n",
    "    x_train = train_data.iloc[:, :-1]\n",
    "    y_train = train_data.iloc[:, -1]\n",
    "    x_test = test_data.iloc[:, :-1]\n",
    "    y_test = test_data.iloc[:, -1]\n",
    "    print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "    # 2-2 样本不均衡问题处理\n",
    "    classes_weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "    # 3 xgb模型训练\n",
    "    estimator = xgb.XGBClassifier(n_estimators=100, objective='multi:softmax',\n",
    "                                  eval_metric='merror', eta=0.1, use_label_encoder=False, random_state=22)\n",
    "    # 训练的时候，指定样本的权重\n",
    "    estimator.fit(x_train, y_train, sample_weight=classes_weights)\n",
    "\n",
    "    # 4 xgb模型评估\n",
    "    y_pred = estimator.predict(x_test)\n",
    "    print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def dm04_交叉验证网格搜索():\n",
    "    # 1 加载数据集\n",
    "    train_data = pd.read_csv('C:/Users/王晋华/Desktop/红酒品质分类-train.csv')\n",
    "    test_data = pd.read_csv('C:/Users/王晋华/Desktop/红酒品质分类-test.csv')\n",
    "\n",
    "    # 2 准备数据 训练集测试集\n",
    "    x_train = train_data.iloc[:, :-1]\n",
    "    y_train = train_data.iloc[:, -1]\n",
    "    x_test = test_data.iloc[:, :-1]\n",
    "    y_test = test_data.iloc[:, -1]\n",
    "    print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "    # 3 交叉验证时,采用分层抽取\n",
    "    spliter = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    # 4 模型训练\n",
    "    # 4-1 定义超参数\n",
    "    param_grid = {'max_depth': np.arange(3, 5, 1),\n",
    "                  'n_estimators': np.arange(50, 150, 50),\n",
    "                  'eta': np.arange(0.1, 1, 0.3)}\n",
    "\n",
    "    # 4-2 实例化xgb\n",
    "    estimator = xgb.XGBClassifier(n_estimators=100,\n",
    "                                  objective='multi:softmax',\n",
    "                                  eval_metric='merror',\n",
    "                                  eta=0.1,\n",
    "                                  use_label_encoder=False,\n",
    "                                  random_state=22)\n",
    "\n",
    "    # 4-2 实例化cv工具 (原代码注释有重复，此处按逻辑修正)\n",
    "    estimator = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=spliter)\n",
    "\n",
    "    # 4-3 训练模型\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    # 5 模型评估\n",
    "    y_pred = estimator.predict(x_test)\n",
    "    print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "    print('estimator.best_estimator_-->', estimator.best_estimator_)\n",
    "    print('estimator.best_params_-->', estimator.best_params_)\n",
    "if __name__ == '__main__':\n",
    "    dm01_realdata()\n",
    "    dm02_训练模型()\n",
    "    dm03_训练模型()\n",
    "    dm04_交叉验证网格搜索()"
   ],
   "id": "809cead37a0221a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1279, 12) (1279,) (320, 12) (320,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.70      0.82      0.75       136\n",
      "           3       0.64      0.63      0.64       128\n",
      "           4       0.65      0.50      0.56        40\n",
      "           5       0.33      0.33      0.33         3\n",
      "\n",
      "    accuracy                           0.67       320\n",
      "   macro avg       0.39      0.38      0.38       320\n",
      "weighted avg       0.64      0.67      0.65       320\n",
      "\n",
      "(1279, 12) (1279,) (320, 12) (320,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.25      0.18      0.21        11\n",
      "           2       0.71      0.84      0.77       136\n",
      "           3       0.67      0.55      0.60       128\n",
      "           4       0.46      0.47      0.47        40\n",
      "           5       0.17      0.33      0.22         3\n",
      "\n",
      "    accuracy                           0.64       320\n",
      "   macro avg       0.38      0.40      0.38       320\n",
      "weighted avg       0.64      0.64      0.64       320\n",
      "\n",
      "(1279, 12) (1279,) (320, 12) (320,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.33      0.09      0.14        11\n",
      "           2       0.70      0.82      0.76       136\n",
      "           3       0.66      0.63      0.65       128\n",
      "           4       0.68      0.57      0.62        40\n",
      "           5       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.68       320\n",
      "   macro avg       0.48      0.41      0.43       320\n",
      "weighted avg       0.67      0.68      0.67       320\n",
      "\n",
      "estimator.best_estimator_--> XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eta=np.float64(0.4),\n",
      "              eval_metric='merror', feature_types=None, feature_weights=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=np.int64(4), max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=np.int64(100), n_jobs=None, ...)\n",
      "estimator.best_params_--> {'eta': np.float64(0.4), 'max_depth': np.int64(4), 'n_estimators': np.int64(100)}\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
